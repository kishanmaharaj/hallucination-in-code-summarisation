{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bf5a52-d4d7-4e3d-976d-1a992527f309",
   "metadata": {},
   "source": [
    "### Visible device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89e042d-a5a1-4eeb-b1e7-7c8f4a207bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e87060-6b90-45da-af91-bdf98608cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import args\n",
    "import pandas as pd\n",
    "from prompts import summary_generation\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.inference_helper import inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2b87c-3d80-4f4e-8e4f-8abac65636d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(args):\n",
    "    model_name = [\"llama3_8b\", \"llama3_70b\", \"ibm_granite_3b\", \"ibm_granite_8b\", \"ibm_granite_20b\", \"ibm_granite_34b\"][1]\n",
    "    device=\"cuda\"\n",
    "    device_auto=True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf449b2-cf4e-4097-a4a4-a8420219c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = getattr(args, args.model_name)\n",
    "prompt = getattr(summary_generation, args.model_name)\n",
    "\n",
    "java_code = list(pd.read_csv(args.processed_data)['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d73501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "if current_model['cached']:\n",
    "    print(\"Using cached version\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(current_model[\"tokenizer\"], cache_dir=args.cache_dir, device_map = 'auto') \n",
    "    model = AutoModelForCausalLM.from_pretrained(current_model[\"model_path\"], cache_dir=args.cache_dir, device_map = 'auto') \n",
    "\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(current_model[\"tokenizer\"], device_map = 'auto')\n",
    "    model = AutoModelForCausalLM.from_pretrained(current_model[\"model_path\"], device_map = 'auto')\n",
    "# device = args.device\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a66e0c-3d38-4017-aa20-7aa44611449d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [14:09:54<00:00, 84.99s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_summaries = []\n",
    "\n",
    "for i in tqdm(range(0, len(java_code))):\n",
    "    \n",
    "    current_prompt = prompt.format(java_code[i])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = inference(tokenizer=tokenizer, model=model, prompt=current_prompt)\n",
    "\n",
    "    generated_summaries.append(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15d869-bbcf-4534-9bd9-7036bfd5266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.DataFrame()\n",
    "\n",
    "summaries['codeXGlue_Java_code'] = java_code\n",
    "summaries['generated_summaries_{}'.format(args.model_name)] = generated_summaries\n",
    "summaries.to_csv('./saved_data/generated_summaries/generated_summaries_{}.csv'.format(args.model_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hallucination]",
   "language": "python",
   "name": "conda-env-hallucination-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
