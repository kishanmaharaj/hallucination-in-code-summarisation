{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8aa2d0-910b-43d0-96c4-daf02adceaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d1e10d-f017-4490-bd17-391b190e54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990e4cad-ffb8-45df-95a0-ae57e3c5fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from args import args\n",
    "from prompts import entity_recognition\n",
    "from utils import codexglue_helper\n",
    "from utils.inference_helper import inference, update_file_name, reload_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1461d743-1bce-4d5d-a2c8-4ff92ff0eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(args):\n",
    "    model_name = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"ibm_granite_3b\", \"ibm_granite_8b\", \"ibm_granite_20b\", \"ibm_granite_34b\", \"star_coder2_15b\", \"codellama_7b\", \"codellama_34b\"][1]\n",
    "    device = \"cuda\"\n",
    "    device_auto = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6675bc1e-4cf3-4a78-8149-4c4442e1f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = getattr(args, args.model_name)\n",
    "print(current_model)\n",
    "prompt = getattr(entity_recognition, args.model_name)\n",
    "\n",
    "## Load the generated summaries\n",
    "generated_summary = pd.read_csv('./saved_data/generated_summaries/generated_summaries_{}.csv'.format(args.model_name))\n",
    "generated_summary = list(generated_summary['generated_summaries_{}'.format(args.model_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17105947-d79f-4478-a543-ad69958f5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "if current_model['cached']:\n",
    "    print(\"Using cached version\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(current_model[\"tokenizer\"], cache_dir=args.cache_dir, device_map = 'auto')\n",
    "    model = AutoModelForCausalLM.from_pretrained(current_model[\"model_path\"], cache_dir=args.cache_dir, device_map = 'auto')\n",
    "\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(current_model[\"tokenizer\"], device_map = 'auto')\n",
    "    model = AutoModelForCausalLM.from_pretrained(current_model[\"model_path\"], device_map = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a66e0c-3d38-4017-aa20-7aa44611449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ner = []\n",
    "\n",
    "for i in tqdm(range(len(generated_summary))):\n",
    "    current_prompt = prompt.replace('{generated_summary}', generated_summary[i])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = inference(tokenizer=tokenizer, model=model, prompt=current_prompt)\n",
    "\n",
    "    predicted_ner.append(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc180c51-fd5d-4041-bed9-2eec30357be9",
   "metadata": {},
   "source": [
    "### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3027d9-9e54-4e9a-8936-ad59f0b15658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ner_out = pd.DataFrame()\n",
    "\n",
    "ner_out['summaries_{}'.format(args.model_name)] = generated_summary\n",
    "ner_out['predicted_ner_{}'.format(args.model_name)] = predicted_ner\n",
    "ner_out.to_csv('./saved_data/entity_recognition_output/predicted_ner_{}.csv'.format(args.model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2be25-dd19-4f9f-8819-1defebf3d58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hallucination]",
   "language": "python",
   "name": "conda-env-hallucination-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
