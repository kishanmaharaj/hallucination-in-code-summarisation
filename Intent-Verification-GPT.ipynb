{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce323b67-9234-43c6-8732-6fe73a23b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff554b7-522d-44a3-941c-4b012c4d738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import args\n",
    "from utils.string_helper import get_relevant_sents\n",
    "from utils.tokenizer import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b3554d5-ff9a-4da4-9930-d52c54215f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args(args):\n",
    "    model_name = [\"llama3_8b\", \"llama3_70b\", \"mistral_7b\", \"ibm_granite_20b\", \"ibm_granite_34b\", \"codellama_7b\", \"codellama_34b\"][6]\n",
    "    device = \"cuda\"\n",
    "    device_auto = True\n",
    "    evaluated_summary_path = \"./saved_data/evaluated_summary/evaluated_summary_{}.csv\"\n",
    "    summary_path = './saved_data/generated_summaries/generated_summaries_{}.csv'\n",
    "    action_verification_path = \"./saved_data/gpt_evaluations/action_verification_entity_level/gpt_action_verification_for_{}.csv\"\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"use_nltk\": True,\n",
    "    \"drop_stopword\": True,\n",
    "    \"drop_punct\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3807754",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4 = \"API_KEY\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=gpt_4,\n",
    ")\n",
    "\n",
    "gpt_version = \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64204e-faee-4a52-8464-884bc53b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = args.evaluated_summary_path.format(args.model_name)\n",
    "print(summary_path)\n",
    "summary_df = pd.read_csv(summary_path)\n",
    "java_code = list(summary_df['java_code'])\n",
    "summaries = list(summary_df['summary'])\n",
    "unmapped_entities = [eval(x) for x in list(summary_df['unmapped_entities'])]\n",
    "mapped_entities = [eval(x) for x in list(summary_df['mapped_entities'])]\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe8fba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "Assume you are an expert in understanding JAVA code. \n",
    "\n",
    "Your task is to verify whether the description of '{mapped_entity}' in the given text is correct, incorrect, or irrelevant with respect to the code.\n",
    "Only output one of the following labels: [\"CORRECT\", \"INCORRECT\", \"IRRELEVANT\"].\n",
    "Do not provide any other details.\n",
    "\n",
    "Description:\n",
    "{relevant_sent}\n",
    "\n",
    "\n",
    "[CODE]\n",
    "{CODE}\n",
    "[/CODE]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bef157a-dccf-432c-a02a-0205c706d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_file_name(filename, data_folder='./saved_data/gpt_evaluations/action_verification_entity_level/'):\n",
    "    \"\"\"\n",
    "    Updates the file name based on the current contents of the given directory -> Avoids overwriting\n",
    "    ----------\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: string\n",
    "    Specified file name\n",
    "    \n",
    "    log_path: string\n",
    "    Specified data directory\n",
    "    ----------\n",
    "    Returns the generated text\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_content = list(os.listdir(data_folder))\n",
    "    run = 1\n",
    "    extension = \".csv\"\n",
    "\n",
    "    while filename.split(extension)[0][:-1]+str(\"_run_\")+str(run)+extension in  folder_content:\n",
    "        run = run+1\n",
    "            \n",
    "    return filename.split(extension)[0][:-1]+str(\"_run_\")+str(run)+extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad894178-39a9-4615-8614-c0ac536798d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = args.action_verification_path.format(args.model_name)\n",
    "update_file_name(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df7f2f6-3295-49f7-8c14-9d57578bfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fields = [\"java_code\", \"summary_{}\".format(args.model_name),  'mapped_ents_{}'.format(args.model_name), 'gpt_pred_{}'.format(args.model_name)]\n",
    "with open(file_name, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95738e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [1:07:52<00:00,  6.79s/it]\n"
     ]
    }
   ],
   "source": [
    "action_verification = []\n",
    "in_tokens = []\n",
    "out_tokens = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(summaries))):\n",
    "    \n",
    "    current_summary = summaries[i]\n",
    "    current_java_code = java_code[i]\n",
    "    current_mapped_ents = mapped_entities[i]\n",
    "    current_unmapped_entities = unmapped_entities[i]\n",
    "\n",
    "    sent_text, words = tokenize(current_summary.lower(), config) # this gives us a list of sentences\n",
    "\n",
    "    # Only Use the sentences with more than 4 characters\n",
    "    longer_sent = [x for x in sent_text if len(x)>4]\n",
    "\n",
    "    current_verification = {\"summary\":summaries[i], \"java_code\":java_code[i], \"mapped_ents\":current_mapped_ents, \"verification\":[]}\n",
    "\n",
    "    for j in range(len(current_mapped_ents)):\n",
    "    \n",
    "        current_mapped_ent = current_mapped_ents[j]\n",
    "        relevant_sents = get_relevant_sents(longer_sent, current_mapped_ent)\n",
    "        \n",
    "        for relevant_sent in relevant_sents:\n",
    "            current_prompt = prompt.replace(\"{relevant_sent}\", relevant_sent).replace(\"{mapped_entity}\", current_mapped_ent).replace(\"{CODE}\", current_java_code)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\":  current_prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=gpt_version,\n",
    "                max_tokens=100,\n",
    "            )\n",
    "\n",
    "            \n",
    "            current_verdict = response.choices[0].message.content\n",
    "\n",
    "            current_verification[\"verification\"].append({\"mapped_ent\":current_mapped_ent, \"relevant_sent\": relevant_sent, \"verdict\":current_verdict})\n",
    "            \n",
    "            # Maintain token usage data\n",
    "            in_tokens.append(response.usage.prompt_tokens)\n",
    "            out_tokens.append(response.usage.completion_tokens)\n",
    "\n",
    "    action_verification.append(current_verification)\n",
    "\n",
    "\n",
    "    with open(file_name, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        row_data = [current_verification[\"java_code\"], current_verification[\"summary\"],  current_verification[\"mapped_ents\"],  current_verification[\"verification\"]]\n",
    "        csvwriter.writerow(row_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "360c2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_verification_df = pd.DataFrame()\n",
    "\n",
    "# action_verification_df['java_code'] = java_code\n",
    "# action_verification_df['verification_{}'.format(args.model_name)] = verification\n",
    "# action_verification_df['predicted_hallucinations_{}'.format(args.model_name)] = predicted_hallucinations\n",
    "# action_verification_df.to_csv('./saved_data/gpt_evaluations/action_verification_entity_level/gpt_predicted_av_entity_level_{}.csv'.format(args.model_name), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
